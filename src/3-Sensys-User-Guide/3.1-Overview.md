# Sensys Overview

The Sensys monitoring software runs a daemon `orcmd` collecting in-band sensor data from the compute node periodically and sending this to the logical aggregator daemon `orcmd` for data gather, process and store in the database. A master controller daemon `orcmsched` running on the root or head node provides a gateway for configuring the default settings for the monitoring system and constantly monitors the heartbeat status of the aggregator daemons and its corresponding compute node daemons.

The software component consists of the following framework interfaces and plugin implementations:
* cfgi: cluster configuration management interface to read a config file.
* sensor: Sensor data monitoring subsystem interface to read sensors information.
* analytics: Data reduction using user defined workflows.
* db: Database system read and write implementation.
* errmgr: Error manager interface to report errors and events.
* state: State machine for monitoring system
* oob: Out-of-band communication
* routed: Routing table for runtime messaging layer
* rml: Runtime messaging layer (routing of OOB messages)
* diag: System Diagnostics
* scd: Scheduler - Head node of monitoring subsystem
* sst: cluster subsystem initialization
* event: event handler
* hwloc: Hardware locality
* if: network interface
* installdirs: opal build prefix for install folders
* sec: security authentication/authorization

Plugin components can be dynamic or static, that is, they can be available as runtime plugins or they may be compiled statically into libraries.

